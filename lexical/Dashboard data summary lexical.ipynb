{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fdacc8",
   "metadata": {},
   "source": [
    "# Summarize all data for the dashboard\n",
    "***\n",
    "## Workflow\n",
    "1. Imports\n",
    "2. Load data and merge it to a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc99ae8",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e44b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import re\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ee2ebb",
   "metadata": {},
   "source": [
    "## 2. Load data and merge\n",
    "- simple feature\n",
    "- timestamps\n",
    "- sentiments\n",
    "- explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7387ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple word count like features\n",
    "simple_features = pd.read_csv('data/wordcount_uniquewordcount.csv')\n",
    "simple_features.drop(columns=['text_unprocessed', 'tokenize', 'stemming'], inplace = True)\n",
    "simple_features.rename(columns = {'Person':'Participant'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c70974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_extraction(string):\n",
    "    #print(string)\n",
    "    time_stamps = string.replace(']]', '').replace('[[','')\n",
    "    time_stamps = time_stamps.split('], [')\n",
    "    time_stamps = np.array([sub.split(',') for sub in time_stamps])\n",
    "    time_stamps = time_stamps.astype(float)\n",
    "    return time_stamps\n",
    "\n",
    "def fill_nan_timestamps(list_of_lists, length):\n",
    "    # list of timestamps, max length of interview\n",
    "    for i, start_stop in enumerate(list_of_lists):\n",
    "        if np.isnan(start_stop[0]) or np.isnan(start_stop[1]):\n",
    "            if np.isnan(start_stop[0]):\n",
    "                start_stop[0] = 0\n",
    "            elif np.isnan(start_stop[1]):\n",
    "                start_stop[1] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00eea596",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "timestamps = pd.read_csv('data/new_time_stamps.csv')\n",
    "timestamps.drop(columns=['Unnamed: 0', 'tmp1'], inplace = True)\n",
    "timestamps['tokenized_sentences'] = timestamps['tokenized_sentences'].apply(lambda x: ast.literal_eval(x))\n",
    "timestamps['new_time_stamps'] = timestamps['new_time_stamps'].apply(lambda x: timestamp_extraction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee913e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = simple_features.merge(timestamps, on='Participant', validate='one_to_one')\n",
    "merged.apply(lambda x: fill_nan_timestamps(x['new_time_stamps'], x['interview_length']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c66bc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = pd.read_csv('data/explanations_all.csv')\n",
    "explanations.drop(columns=['tokenize_sentence'], inplace = True)\n",
    "explanations['explanations'] = explanations['explanations'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "365784d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list(string):\n",
    "    out = re.sub(\"array\\(\", \"\", string) # remove array\n",
    "    out = re.sub(\",\\n[ ]*dtype=float32\\)\", \"\", out) # remove last interviewer statement from text\n",
    "    out = re.sub(\",[ ]*dtype=float32\\)\", \" \", out) # remove last interviewer statement from text\n",
    "    out = re.sub(\"\\n\", \" \", out) # remove last interviewer statement from text\n",
    "    out = re.sub(\"[ ]*,\", \",\", out) # remove last interviewer statement from text\n",
    "    out = re.sub(\"[ ]*]\", \"]\", out) # remove last interviewer statement from text\n",
    "    out = re.sub(\"[ ]{2}\", \" \", out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50ea6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = pd.read_csv('data/MIT_dataset_emotion_prediction_percentage.csv')\n",
    "emotions.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', \n",
    "                       'text_remove_interview_signs', 'tokenize_sentence'], inplace = True)\n",
    "\n",
    "emotions['prediction'] = emotions['prediction'].apply(lambda x: ast.literal_eval(make_list(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48673320",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged.merge(emotions, on='Participant').merge(explanations, on='Participant')\n",
    "df['new_time_stamps'] = df['new_time_stamps'].apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eade9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/full_scores', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1c6bde4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/full_scores')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
