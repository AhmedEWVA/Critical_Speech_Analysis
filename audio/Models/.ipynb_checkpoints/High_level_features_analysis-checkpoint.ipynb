{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_lanxhQQAyM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import math\n",
    "\n",
    "import dill\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Neural networks can be constructed using the torch.nn package.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkXtZrpeQL36"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D80boxYoQLyu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOEbvHhyQLwZ"
   },
   "outputs": [],
   "source": [
    "dir = \"drive/MyDrive/Colab_Notebooks/mit_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wA-BvgMmQLuA"
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(dir+\"/high_level_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qms6FEFTK0_F"
   },
   "outputs": [],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw2yZeJZQLrq"
   },
   "outputs": [],
   "source": [
    "def high_level_features (files, mydf, target_label, target_column):\n",
    "    n = len(files)\n",
    "    df = pd.DataFrame(columns=[\"Participant\", \"simple_feature_dict\", target_label], dtype=object)\n",
    "    \n",
    "    labels_df_raw = pd.read_csv(dir+\"/Labels/turker_scores_full_interview.csv\")\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        labels_audio = ['Worker',target_label]#,'NotAwkward','Excited','SpeakingRate','NoFillers','Friendly','EngagingTone','Calm','NotStressed']\n",
    "        bis = labels_df_raw.loc[labels_df_raw[\"Participant\"] == files[i].lower() ,]\n",
    "        bis = bis.reindex(columns = labels_audio)\n",
    "        \n",
    "        score = bis.loc[bis[\"Worker\"] == 'AGGR' ,[target_label]].values[0,0]\n",
    "        \n",
    "        x = mydf.loc[mydf[\"Participant\"] == files[i] ,[target_column]].values[0,0]\n",
    "        #speech = mydf.loc[mydf[\"Participant\"] == files[i] ,[\"rate_of_speech\"]].values[0,0]\n",
    "        #articulation = mydf.loc[mydf[\"Participant\"] == files[i] ,[\"articulation_rate\"]].values[0,0]\n",
    "        #print(x, type(x))\n",
    "        try:\n",
    "            x = float(x)\n",
    "        except ValueError:\n",
    "            x = 0\n",
    "            print(\"Not a float\")\n",
    "            continue\n",
    "        df = df.append({\"Participant\":files[i], \"simple_feature_dict\":{\"target\":x} , target_label:score}, ignore_index=True)\n",
    "      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqn6IAlpQ_7G"
   },
   "outputs": [],
   "source": [
    "files_interv = ['PP89', 'PP76', 'PP62', 'P67', 'P73', 'P8', 'P72', 'P66', 'PP63', 'PP77', 'PP61', 'PP49', 'P70', 'P64', 'P58', 'P59', 'P65', 'P71', 'PP48', 'PP74', 'PP60', 'PP58', 'PP64', 'PP70', 'P49', 'P61', 'P60', 'P74', 'P48', 'PP71', 'PP65', 'PP59', 'PP73', 'PP67', 'P62', 'P76', 'P89', 'P77', 'P63', 'PP66', 'PP72', 'PP15', 'PP29', 'P10', 'P11', 'PP14', 'PP16', 'P13', 'P12', 'PP17', 'PP8', 'PP13', 'P16', 'P17', 'PP12', 'PP10', 'P29', 'P15', 'P14', 'PP11', 'PP34', 'PP20', 'PP7', 'P25', 'P31', 'P30', 'P24', 'PP6', 'PP21', 'PP35', 'PP37', 'PP4', 'P32', 'P27', 'P33', 'PP5', 'PP22', 'PP1', 'PP32', 'P37', 'P22', 'PP33', 'PP27', 'PP31', 'PP25', 'P20', 'P34', 'P35', 'P21', 'PP24', 'PP30', 'PP3', 'PP80', 'PP57', 'PP43', 'P52', 'P85', 'P1', 'P84', 'P53', 'P47', 'PP42', 'PP56', 'PP81', 'PP83', 'P45', 'P79', 'P86', 'P3', 'P78', 'P44', 'P50', 'PP69', 'PP55', 'PP86', 'PP79', 'PP45', 'P83', 'P7', 'P6', 'P55', 'P69', 'PP50', 'PP44', 'PP78', 'PP85', 'PP52', 'P43', 'P57', 'P80', 'P4', 'P5', 'P81', 'P56', 'P42', 'PP47', 'PP53', 'PP84']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXdhph1ulR9o"
   },
   "outputs": [],
   "source": [
    "def simple_aggregate(series):\n",
    "    my_list = []\n",
    "\n",
    "    out = {\n",
    "        'target': my_list,\n",
    "    }\n",
    "    for dict in series:\n",
    "        my_list.append(dict.get('target'))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGFh8gZxK_sZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqTEvfcdQLpi"
   },
   "outputs": [],
   "source": [
    "target_label = \"SpeakingRate\"\n",
    "target_feature = \"articulation_rate\"\n",
    "df_Test = high_level_features (files_interv, dataset_df, target_label,target_feature)\n",
    "\n",
    "index_good_interviews = df_Test[target_label].rank(pct=True) > 0.75\n",
    "index_bad_interviews = df_Test[target_label].rank(pct=True) <= 0.25\n",
    "\n",
    "dict_good_simple = df_Test[index_good_interviews]['simple_feature_dict'].aggregate(simple_aggregate)\n",
    "dict_bad_simple = df_Test[index_bad_interviews]['simple_feature_dict'].aggregate(simple_aggregate)\n",
    "\n",
    "good_bad = pd.concat(axis=0, ignore_index=True, objs=[\n",
    "    pd.DataFrame.from_dict({'value': dict_bad_simple.get('target'), target_label: 'no'}),\n",
    "    pd.DataFrame.from_dict({'value': dict_good_simple.get('target'), target_label: 'yes'})\n",
    "])\n",
    "\n",
    "random_bad_interview = dataset_df[index_bad_interviews].sample()\n",
    "random_good_interview = dataset_df[index_good_interviews].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqa6f56RB1Vv"
   },
   "outputs": [],
   "source": [
    "df_Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYEue25GQLm9"
   },
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(1, 1, figsize=(15, 9))\n",
    "# Angry\n",
    "sns.kdeplot(data=good_bad, hue=target_label, x='value', fill=True, common_norm=False).set(title=target_feature)\n",
    "plt.axvline(float(random_bad_interview[target_feature].iloc[0]), color='red')\n",
    "plt.axvline(float(random_good_interview[target_feature].iloc[0]), color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2iVqYJ2QoeK"
   },
   "outputs": [],
   "source": [
    "np.percentile(np.array(dict_good_simple['target']),95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lg21qo-8X43n"
   },
   "outputs": [],
   "source": [
    "np.percentile(np.array(dict_good_simple['target']),15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArgdtbQZX40j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9HCiuH1X4x-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWoNhAiAQob0"
   },
   "outputs": [],
   "source": [
    "target_label = \"SpeakingRate\"\n",
    "target_feature = \"rate_of_speech\"\n",
    "df_Test = high_level_features (files_interv, dataset_df, target_label,target_feature)\n",
    "\n",
    "index_good_interviews = df_Test[target_label].rank(pct=True) > 0.75\n",
    "index_bad_interviews = df_Test[target_label].rank(pct=True) <= 0.25\n",
    "\n",
    "dict_good_simple = df_Test[index_good_interviews]['simple_feature_dict'].aggregate(simple_aggregate)\n",
    "dict_bad_simple = df_Test[index_bad_interviews]['simple_feature_dict'].aggregate(simple_aggregate)\n",
    "\n",
    "good_bad = pd.concat(axis=0, ignore_index=True, objs=[\n",
    "    pd.DataFrame.from_dict({'value': dict_bad_simple.get('target'), target_label: 'no'}),\n",
    "    pd.DataFrame.from_dict({'value': dict_good_simple.get('target'), target_label: 'yes'})\n",
    "])\n",
    "\n",
    "random_bad_interview = dataset_df[index_bad_interviews].sample()\n",
    "random_good_interview = dataset_df[index_good_interviews].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RGdBsUEQoY8"
   },
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(1, 1, figsize=(15, 9))\n",
    "# Angry\n",
    "sns.kdeplot(data=good_bad, hue=target_label, x='value', fill=True, common_norm=False).set(title=target_feature)\n",
    "plt.axvline(float(random_bad_interview[target_feature].iloc[0]), color='red')\n",
    "plt.axvline(float(random_good_interview[target_feature].iloc[0]), color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyB8yr1URrjz"
   },
   "outputs": [],
   "source": [
    "np.percentile(np.array(dict_good_simple['target']),15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqTdxe8uQoWW"
   },
   "outputs": [],
   "source": [
    "np.percentile(np.array(dict_good_simple['target']),90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MTBQfnH8YqCm"
   },
   "outputs": [],
   "source": [
    "dict_good_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ww4P83sPYp_w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geq9bF1mYp9k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZrPEaM4QoTd"
   },
   "outputs": [],
   "source": [
    "target_label = \"RecommendHiring\"\n",
    "target_feature = \"balance\"\n",
    "df_Test = high_level_features (files_interv, dataset_df, target_label,target_feature)\n",
    "\n",
    "index_good_interviews = df_Test[target_label].rank(pct=True) > 0.75\n",
    "index_bad_interviews = df_Test[target_label].rank(pct=True) <= 0.25\n",
    "\n",
    "dict_good_simple = df_Test[index_good_interviews]['simple_feature_dict'].aggregate(simple_aggregate)\n",
    "dict_bad_simple = df_Test[index_bad_interviews]['simple_feature_dict'].aggregate(simple_aggregate)\n",
    "\n",
    "good_bad = pd.concat(axis=0, ignore_index=True, objs=[\n",
    "    pd.DataFrame.from_dict({'value': dict_bad_simple.get('target'), 'RecommendHiring': 'no'}),\n",
    "    pd.DataFrame.from_dict({'value': dict_good_simple.get('target'), 'RecommendHiring': 'yes'})\n",
    "])\n",
    "\n",
    "random_bad_interview = dataset_df[index_bad_interviews].sample()\n",
    "random_good_interview = dataset_df[index_good_interviews].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7e4nv5KSNai"
   },
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(1, 1, figsize=(15, 9))\n",
    "# Angry\n",
    "sns.kdeplot(data=good_bad, hue=target_label, x='value', fill=True, common_norm=False).set(title=target_feature)\n",
    "plt.axvline(float(random_bad_interview[target_feature].iloc[0]), color='red')\n",
    "plt.axvline(float(random_good_interview[target_feature].iloc[0]), color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "330soXT9ls1d"
   },
   "outputs": [],
   "source": [
    "np.percentile(np.array(dict_good_simple['target']),75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYu_CgfuY3qg"
   },
   "outputs": [],
   "source": [
    "np.percentile(np.array(dict_good_simple['target']),25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40CrMN0hY7M4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKxJOIWcc/EAtCadJ/EoSk",
   "name": "my_prosody.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
